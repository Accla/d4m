This example uses mapreduce and cloudbase to compute word counts for a set of
documents.  This is accomplished using a map only map reduce job and a
cloudbase table with aggregators.

To run this example you will need a directory in HDFS containing text files.
The cloudbase readme will be used to show how to run this example.

  [username@host cloudbase-examples]$ hadoop fs -ls /user/username/wc
  Found 1 items
  -rw-r--r--   2 username supergroup       9359 2009-07-15 17:54 /user/username/wc/Cloudbase.README

The first part of running this example is to create a table with aggregation
for the column family count.

  [username@host bin]$ ./cloudbase.sh shell <username>
  Enter current password for '<username>': *****
  CBShell 1.0.0-RC2 - type 'help' for a list of available commands
  > createtable wordCount AGG count cloudbase.core.aggregation.StringSummation
  wordCount>
  
After creating the table, run the word count map reduce job.

  BIN=../bin
  LIB=../lib
  VERSION=1.0.0-RC2
  MYLIBJARS="-libjars $LIB/cloudbase-core-$VERSION.jar,$LIB/thrift-20080411p1.jar,$LIB/zookeeper-3.1.0.jar"
  MYJAR=$LIB/cloudbase-examples-$VERSION.jar
  MYCLASS=cloudbase.examples.mapreduce.WordCount
  
*NOTE: Use the following command for Hadoop 0.20.0
  [username@host cloudbase-examples]$  hadoop jar $MYJAR $MYCLASS $MYLIBJARS localhost /user/username/wc wordCount

*NOTE: Use the following command for Hadoop 0.19.1
  [username@host cloudbase-examples]$  hadoop jar $MYLIBJARS $MYJAR $MYCLASS localhost /user/username/wc wordCount
  09/07/16 09:02:01 WARN mapred.JobClient: Use genericOptions for the option -libjars
  09/07/16 09:02:01 INFO mapred.FileInputFormat: Total input paths to process : 1
  09/07/16 09:02:02 INFO mapred.JobClient: Running job: job_200907061203_0027
  09/07/16 09:02:03 INFO mapred.JobClient:  map 0% reduce 0%
  09/07/16 09:02:11 INFO mapred.JobClient:  map 50% reduce 0%
  09/07/16 09:02:14 INFO mapred.JobClient:  map 100% reduce 0%
  09/07/16 09:02:17 INFO mapred.JobClient: Job complete: job_200907061203_0027
  09/07/16 09:02:17 INFO mapred.JobClient: Counters: 6
  09/07/16 09:02:17 INFO mapred.JobClient:   File Systems
  09/07/16 09:02:17 INFO mapred.JobClient:     HDFS bytes read=12873
  09/07/16 09:02:17 INFO mapred.JobClient:   Job Counters 
  09/07/16 09:02:17 INFO mapred.JobClient:     Launched map tasks=2
  09/07/16 09:02:17 INFO mapred.JobClient:     Data-local map tasks=2
  09/07/16 09:02:17 INFO mapred.JobClient:   Map-Reduce Framework
  09/07/16 09:02:17 INFO mapred.JobClient:     Map input records=203
  09/07/16 09:02:17 INFO mapred.JobClient:     Map input bytes=9359
  09/07/16 09:02:17 INFO mapred.JobClient:     Map output records=1388
  
After the map reduce job completes, query the cloudbase table to see word
counts.

  [username@host bin]$ ./cloudbase.sh shell <username>
  Enter current password for '<username>': *****
  CBShell 1.0.0-RC2 - type 'help' for a list of available commands
  > table wordCount
  Connecting as user: 
  wordCount> scan the
  the count:20080906 CNF[]        70
  their count:20080906 CNF[]      1
  them count:20080906 CNF[]       1
  then count:20080906 CNF[]       1
  there count:20080906 CNF[]      1
  these count:20080906 CNF[]      3
  things count:20080906 CNF[]     1
  this count:20080906 CNF[]       8

  
